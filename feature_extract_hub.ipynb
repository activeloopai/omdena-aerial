{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "environment": {
      "name": "pytorch-gpu.1-4.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
    },
    "kernelspec": {
      "display_name": "predicting-poverty-replication",
      "language": "python",
      "name": "predicting-poverty-replication"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "feature-extract-hub 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WthoyGcu2r88",
        "colab_type": "text"
      },
      "source": [
        "Using the images marked as valid per cluster, we pass them through the CNN and extract their feature vectors. the results are stored at a per-country basis. For example, all Malawi feature extractions will go into results/malawi_2016/cnn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7wE1YPB_KhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDlc8OhToeIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In case you haven't registered before on hub before. Run this cell\n",
        "!hub register"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqDK2pMX_Ntp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!hub login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej-HOn762r89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rvxiIJ02r9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = '.'\n",
        "COUNTRIES_DIR = os.path.join(BASE_DIR, 'data', 'countries')\n",
        "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
        "CNN_TRAIN_IMAGE_DIR = os.path.join(BASE_DIR, 'data', 'cnn_images')\n",
        "CNN_DIR = os.path.join(BASE_DIR, 'models', 'trained_model.pt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4MjUtF12r9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "for country in ['malawi_2016', 'ethiopia_2015', 'nigeria_2015']:\n",
        "    os.makedirs(os.path.join(RESULTS_DIR, country), exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCcftitA2r9J",
        "colab_type": "text"
      },
      "source": [
        "# Feature extract with CNN\n",
        "If you have run this step before, you can skip it and run the commented out code in the next section to quick-start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewiyqh4u2r9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_images = pd.read_csv(os.path.join(PROCESSED_DIR, 'image_download_actual.csv'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEQsmPZa2r9M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "ad6170e3-6979-4eec-cb71-d86e02bb8356"
      },
      "source": [
        "df_images.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>image_lat</th>\n",
              "      <th>image_lon</th>\n",
              "      <th>cluster_lat</th>\n",
              "      <th>cluster_lon</th>\n",
              "      <th>cons_pc</th>\n",
              "      <th>nightlights</th>\n",
              "      <th>country</th>\n",
              "      <th>nightlights_bin</th>\n",
              "      <th>is_train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.759163226605976_5.602468666465976_13.714247...</td>\n",
              "      <td>13.759163</td>\n",
              "      <td>5.602469</td>\n",
              "      <td>13.714247</td>\n",
              "      <td>5.557553</td>\n",
              "      <td>1.667379</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ng</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.485523598426016_3.288079612774024_6.51546744...</td>\n",
              "      <td>6.485524</td>\n",
              "      <td>3.288080</td>\n",
              "      <td>6.515467</td>\n",
              "      <td>3.332995</td>\n",
              "      <td>14.054602</td>\n",
              "      <td>12.430817</td>\n",
              "      <td>ng</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-13.222906_33.877838764205976_-13.222906_33.83...</td>\n",
              "      <td>-13.222906</td>\n",
              "      <td>33.877839</td>\n",
              "      <td>-13.222906</td>\n",
              "      <td>33.832923</td>\n",
              "      <td>1.809202</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>mw</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-13.202325078598008_33.93874615719602_-13.2172...</td>\n",
              "      <td>-13.202325</td>\n",
              "      <td>33.938746</td>\n",
              "      <td>-13.217297</td>\n",
              "      <td>33.968690</td>\n",
              "      <td>2.155243</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>mw</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.552117002565977_3.2219584555639833_6.5072012...</td>\n",
              "      <td>6.552117</td>\n",
              "      <td>3.221958</td>\n",
              "      <td>6.507201</td>\n",
              "      <td>3.192015</td>\n",
              "      <td>3.832372</td>\n",
              "      <td>3.141591</td>\n",
              "      <td>ng</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          image_name  ...  is_train\n",
              "0  13.759163226605976_5.602468666465976_13.714247...  ...     False\n",
              "1  6.485523598426016_3.288079612774024_6.51546744...  ...     False\n",
              "2  -13.222906_33.877838764205976_-13.222906_33.83...  ...     False\n",
              "3  -13.202325078598008_33.93874615719602_-13.2172...  ...     False\n",
              "4  6.552117002565977_3.2219584555639833_6.5072012...  ...     False\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzmMfVXA2r9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22c25a95-8b4b-492b-83de-cb5a33ecd151"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using {device} as backend')\n",
        "model = torch.load(CNN_DIR, map_location=device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu as backend\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUlAZePk2r9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7f178ea7-de20-4a25-9124-0b179fa29545"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkjreiQd2r9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rip off the final layers\n",
        "model.classifier = model.classifier[:4]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze8ISZxY2r9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "249daba9-5203-46ed-ba01-3b7538b9c7b7"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I405ZSk9_Dc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hub import Transform, dataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0y14wn39_i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "class ValTransformer(Transform):\n",
        "    def meta(self):\n",
        "        return {\n",
        "            \"nightlights_bin\": {\"shape\": (1,), \"dtype\": \"int\", \"dtag\" : \"text\"},\n",
        "            \"image\": {\"shape\": (1,), \"dtype\": \"object\", \"chunksize\": 100, \"dtag\" : \"image\"},\n",
        "        }\n",
        "\n",
        "    def forward(self, input):\n",
        "        ds = {}\n",
        "        ds[\"nightlights_bin\"] = np.empty(1, dtype=\"int\")\n",
        "        ds[\"nightlights_bin\"][0] = input[\"nightlights_bin\"]\n",
        "\n",
        "        ds[\"image\"] = np.empty(1, object)\n",
        "        ds[\"image\"][0] = transformer(input[\"image\"])\n",
        "        return ds\n",
        "    \n",
        "def to_pair(input):\n",
        "    sample=input[\"image\"]\n",
        "    target=input[\"nightlights_bin\"]\n",
        "    return (sample,target)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKW6xGgI2r9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "ds = dataset.load(\"omdena/predicting-poverty-replication-full\")\n",
        "\n",
        "# Taking the initial validation subset\n",
        "val_ds = ds[0:7293]\n",
        "val_ds = dataset.generate(ValTransformer(),val_ds)\n",
        "\n",
        "val_ds = val_ds.to_pytorch(to_pair)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(val_ds, batch_size=8,shuffle=False,num_workers=4)\n",
        "\n",
        "\n",
        "model.eval()  \n",
        "classes = [0, 1, 2]\n",
        "# shape of final array will be (num_validation_images, 4096)\n",
        "feats = np.zeros(((~df_images['is_train']).sum(), 4096))\n",
        "image_order = []\n",
        "i = 0\n",
        "\n",
        "for inputs, _ in tqdm(dataloader):\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = model(inputs)\n",
        "    feats[i:i+len(inputs),:] = outputs.cpu().detach().numpy()\n",
        "    i += len(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2Si60qT2r9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXi_ophL2r9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_pass_df = df_images.loc[df_images[\"is_train\"] == False]\n",
        "#forward_pass_df = pd.DataFrame.from_dict({'image_name': image_order, 'feat_index': np.arange(len(image_order))})\n",
        "forward_pass_df['feat_index'] = forward_pass_df.index\n",
        "\n",
        "forward_pass_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZxp90us2r9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_consumption = forward_pass_df"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irbk1kQ-2r9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# have we maintained all validation images?\n",
        "assert len(df_consumption) == (~df_images['is_train']).sum()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-_XTTJE2r9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_consumption.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLiFN-gU2r9k",
        "colab_type": "text"
      },
      "source": [
        "## Aggregate Features\n",
        "For each country, we aggregate the image features per cluster and save them to results/country/cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SYbEIwZ2r9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "country_abbrv = ['mw', 'eth', 'ng']\n",
        "country_dir = ['malawi_2016', 'ethiopia_2015', 'nigeria_2015']\n",
        "\n",
        "for ca, cd in zip(country_abbrv, country_dir):\n",
        "    df_c = df_consumption[df_consumption['country'] == ca]\n",
        "    group = df_c.groupby(['cluster_lat', 'cluster_lon'])\n",
        "    x = np.zeros((len(group), 4096))\n",
        "    cluster_list = [] # the corresponding clusters (lat, lon) to the x aggregate feature array\n",
        "    for i, g in enumerate(group):\n",
        "        lat, lon = g[0]\n",
        "        im_sub = df_consumption[(df_consumption['cluster_lat'] == lat) & (df_consumption['cluster_lon'] == lon)].reset_index(drop=True)\n",
        "        agg_feats = np.zeros((len(im_sub), 4096))\n",
        "        for j, d in im_sub.iterrows():\n",
        "            agg_feats[j,:] = feats[d.feat_index]\n",
        "        agg_feats = agg_feats.mean(axis=0) # averages the features across all images in the cluster\n",
        "\n",
        "        x[i,:] = agg_feats\n",
        "        cluster_list.append([lat, lon])\n",
        "    # save to the correct directory\n",
        "    save_dir = os.path.join(RESULTS_DIR, cd, 'cnn')\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    np.save(os.path.join(save_dir, 'cluster_feats.npy'), x)\n",
        "    pickle.dump(cluster_list, open(os.path.join(save_dir, 'cluster_order.pkl'), 'wb')) \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXRRPWDZ2r9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}